{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "from unicodedata import normalize, category\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source where I get the raw data\n",
    "source_path = 'C:\\\\zomato\\\\source'\n",
    "# Folder where I move the files after processed \n",
    "processed_path='C:\\\\zomato\\\\processed\\\\'\n",
    "# Result folder\n",
    "result_path='C:\\\\zomato\\\\result\\\\'\n",
    "# Areas dataset\n",
    "areas_path='C:\\\\zomato\\\\source\\Areas_in_blore.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to receive informations\n",
    "processed_files = []\n",
    "source_files = []\n",
    "validated_file = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if is csv and loading in the list source_csv_files\n",
    "def check_csv():\n",
    "    for csv_file in os.listdir(source_path):\n",
    "        if csv_file.endswith(\".csv\"):\n",
    "            source_files.append(csv_file)\n",
    "check_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get in processed folder the files name\n",
    "def check_processed():\n",
    "    for processed_file in os.listdir(processed_path):\n",
    "        processed_files.append(processed_file)\n",
    "check_processed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_file_20210528182844.csv', 'data_file_20210527182730.csv', 'data_file_20210527182731.csv', 'data_file_20210528182554.csv']\n"
     ]
    }
   ],
   "source": [
    "# Check in the processed folder if the day's files have already been processed\n",
    "difference = set(processed_files).difference(set(source_files))\n",
    "difference_2 = set(source_files).difference(set(processed_files))\n",
    "list_difference = list(difference.union(difference_2))\n",
    "print(list_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\zomato\\source\\data_file_20210528182844.csv\n",
      "C:\\zomato\\source\\data_file_20210527182730.csv\n",
      "C:\\zomato\\source\\data_file_20210528182554.csv\n"
     ]
    }
   ],
   "source": [
    "# Check if files are empty\n",
    "def check_empty():\n",
    "    for nempty_file in list_difference:\n",
    "        mount_file = source_path + \"\\\\\" + nempty_file\n",
    "        \n",
    "        if (os.stat(mount_file).st_size > 2):\n",
    "            validated_file.append(mount_file)\n",
    "            print(mount_file)\n",
    "check_empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove especial/junk characters from the text. \n",
    "def Remove_Sc(get):\n",
    "    run = get.replace(\"ñ\", \"n\").replace(\"Ñ\", \"N\")\n",
    "    run = re.sub(\"\\\\\\\\n\", \" \",run)\n",
    "    #run = re.sub('[^A-Za-z0-9]+', ' ', get)\n",
    "    run_final = normalize(\"NFKD\", run).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    \n",
    "    # Replace special chars including ( )\n",
    "    run_final=re.sub(\"[^(\\w|\\d|\\s)]|\\?|x(\\d){2}(A|E|I|O|U)\",\"\", run_final)  \n",
    "    return re.sub(\"(A|E|I|O|U){2,20}|(A|E|I|O|U)x(\\d){2}(A|E|I|O|U)\",\"\", run_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-821a707b826b>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bad_area['Type_of_issue'] = 'Invalid Adress'\n",
      "<ipython-input-9-821a707b826b>:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_phone_null['Type_of_issue']=\"phone is null\"\n",
      "<ipython-input-9-821a707b826b>:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_location_null['Type_of_issue']=\"location is null\"\n",
      "<ipython-input-9-821a707b826b>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bad_area['Type_of_issue'] = 'Invalid Adress'\n",
      "<ipython-input-9-821a707b826b>:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_phone_null['Type_of_issue']=\"phone is null\"\n",
      "<ipython-input-9-821a707b826b>:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_location_null['Type_of_issue']=\"location is null\"\n",
      "<ipython-input-9-821a707b826b>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bad_area['Type_of_issue'] = 'Invalid Adress'\n",
      "<ipython-input-9-821a707b826b>:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_phone_null['Type_of_issue']=\"phone is null\"\n",
      "<ipython-input-9-821a707b826b>:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_location_null['Type_of_issue']=\"location is null\"\n"
     ]
    }
   ],
   "source": [
    "for execution in validated_file:\n",
    "    # Dataset with specified columns\n",
    "    df = pd.read_csv(execution, usecols = ['url','address','name','rate','votes','phone','location',\n",
    "                                            'rest_type','dish_liked','cuisines','reviews_list'])\n",
    "    # Dataset to be used for check null values\n",
    "    df_check_error = df\n",
    "    \n",
    "    # mounting the target path\n",
    "    df_out = re.sub('.csv','.out',result_path+os.path.basename(execution))\n",
    "    df_bad = re.sub('.csv','.bad',result_path+os.path.basename(execution))\n",
    "    df_meta = re.sub('.csv','.metadata',result_path+os.path.basename(execution))\n",
    "    \n",
    "    # creating flag for null values in the df_check_error to be use as a filter\n",
    "    df_check_error.loc[df_check_error['phone'].isnull(),'value_is_NaN_phone'] = 'Yes'\n",
    "    df_check_error.loc[df_check_error['phone'].notnull(), 'value_is_NaN_phone'] = 'No'\n",
    "    df_check_error.loc[df_check_error['name'].isnull(),'value_is_NaN_name'] = 'Yes'\n",
    "    df_check_error.loc[df_check_error['name'].notnull(), 'value_is_NaN_name'] = 'No'\n",
    "    df_check_error.loc[df_check_error['location'].isnull(),'value_is_NaN_locat'] = 'Yes'\n",
    "    df_check_error.loc[df_check_error['location'].notnull(), 'value_is_NaN_locat'] = 'No'\n",
    "    \n",
    "    #validations dataset filtering null values to load in the file .bad and metadata\n",
    "    df_phone_null = df_check_error[df_check_error[\"value_is_NaN_phone\"] == 'Yes']\n",
    "    df_name_null = df_check_error[df_check_error[\"value_is_NaN_name\"] == 'Yes']\n",
    "    df_location_null = df_check_error[df_check_error[\"value_is_NaN_locat\"] == 'Yes']\n",
    "\n",
    "# address,reviews_list, name     \n",
    "    # Remove especial/junk characters from the text\n",
    "    # apply the function in each element in the list (comlumns)\n",
    "    df['name']= df['name'].map(Remove_Sc)\n",
    "    df['reviews_list']= df['reviews_list'].map(Remove_Sc)\n",
    "    df['address']= df['address'].map(Remove_Sc)\n",
    "\n",
    "# Phone \n",
    "    # 'n' and 'na' to -1 in order to change the field type to int. considering 'n' and 'na' as not applicable\n",
    "    df['phone'] = df['phone'].replace('n', \"-1\").replace('na', \"-1\").replace('', '-1')\n",
    "    \n",
    "    # Split the phone into two columns when necessary    \n",
    "    df[['contact_number_1', 'contact_number_2']] = df['phone'].str.split('\\r\\n |\\n', n=1, expand=True)\n",
    "    \n",
    "    # Replace + and spaces\n",
    "    df['contact_number_1'] = df['contact_number_1'].apply(lambda a: str(a).replace('+','')).apply(lambda a: str(a).replace(' ','')).apply(lambda a: str(a).replace('\\r',''))\n",
    "    df['contact_number_2'] = df['contact_number_2'].apply(lambda a: str(a).replace('+','')).apply(lambda a: str(a).replace(' ',''))\n",
    "    \n",
    "# Validation Areas\n",
    "    #Validation of location field for correctness of data by looking up to the Areas_in_blore.csv file.\n",
    "    df_area = pd.read_excel(areas_path,  engine='openpyxl')\n",
    "    df['check_area'] = df.location.isin(df_area.Area).astype(int)  \n",
    "    df_out_area = df.loc[df['check_area'] == 1]\n",
    "    df_bad_area = df.loc[df['check_area'] == 0]\n",
    "    \n",
    "    df_bad_address = df_bad_area[df_bad_area[\"check_area\"] == 0]\n",
    "    \n",
    "    #df_bad_address = df_bad_area\n",
    "    df_bad_area.index.names = ['Row_num_list']\n",
    "    \n",
    "# Write .bad and metadata whit trash datas\n",
    "    # check If the dataframe has bad_area\n",
    "    if(df_bad_area['name'].count() >= 1):\n",
    "            #load bad data to .bad and problem types in metadata file\n",
    "            df_bad_address.to_csv(df_bad,index=0)\n",
    "            df_bad_area['Type_of_issue'] = 'Invalid Adress'\n",
    "            df_bad_area['Type_of_issue'].to_csv(df_meta)\n",
    "            \n",
    "    if (df_phone_null['value_is_NaN_phone'].count() >= 1):\n",
    "            ##Capturing all the bad records to a .bad & metadata file.\n",
    "            df_phone_null.to_csv(df_bad, mode='a', header=False, index=1)\n",
    "            df_phone_null['Type_of_issue']=\"phone is null\"\n",
    "            df_phone_null['Type_of_issue'].to_csv(df_meta, mode='a', header=False,index=1)\n",
    "            \n",
    "    if (df_name_null['value_is_NaN_name'].count() >= 1):\n",
    "            ##Capturing all the bad records to a .bad & metadata file.\n",
    "            df_name_null.to_csv(df_bad, mode='a', header=False, index=1)\n",
    "            df_name_null['Type_of_issue']=\"Name is null\"\n",
    "            df_name_null['Type_of_issue'].to_csv(df_meta, mode='a', header=False,index=1)\n",
    "            \n",
    "    if (df_location_null['value_is_NaN_locat'].count() >= 1):\n",
    "            ##Capturing all the bad records to a .bad & metadata file.\n",
    "            df_location_null.to_csv(df_bad, mode='a', header=False, index=1)\n",
    "            df_location_null['Type_of_issue']=\"location is null\"\n",
    "            df_location_null['Type_of_issue'].to_csv(df_meta, mode='a', header=False,index=1)   \n",
    "            \n",
    "\n",
    "    # set columns that cannot have null values\n",
    "    df_out_area = df_out_area.loc[df['name'].notnull()]\n",
    "    df_out_area = df_out_area.loc[df['phone'].notnull()]\n",
    "    df_out_area = df_out_area.loc[df['location'].notnull()]    \n",
    "    \n",
    "    #change type\n",
    "    df_out_area['contact_number_1'] = df_out_area['contact_number_1'].astype('int64')\n",
    "    \n",
    "    df_final_out = df_out_area[['url','address','name','rate','votes','contact_number_1','contact_number_2','location',\n",
    "                                            'rest_type','dish_liked','cuisines','reviews_list']]\n",
    "    \n",
    "    # Load the out file\n",
    "    df_final_out.to_csv(df_out,index=0)\n",
    "    \n",
    "    #Copy the processed files in the processor folder to be used in the verification of new files\n",
    "    shutil.copyfile(execution, processed_path+os.path.basename(execution))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
